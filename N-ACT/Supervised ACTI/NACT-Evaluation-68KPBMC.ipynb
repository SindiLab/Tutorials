{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NACT-Pytorch Tutorial: Classifying NeuroCOVID scRNAseq\n",
    "\n",
    "In this notebook, we will go over how to load a pre-trained NACT model, and how to make predictions and evaluate the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in pre-trained NACT model\n",
    "\n",
    "Since our implementation is in pytorch, we can use the `load` funtion that pytorch provides. Our model is stored as a dict, with `epoch` corresponding to the current epoch, and `Saved_Model` corresponding to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFAttentionClassifier(\n",
      "  (layer0): Linear(in_features=17789, out_features=100, bias=True)\n",
      "  (attention0): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (layer1): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (attention1): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (layer2): Linear(in_features=50, out_features=25, bias=True)\n",
      "  (attention2): Linear(in_features=25, out_features=25, bias=True)\n",
      "  (out_layer): Linear(in_features=25, out_features=11, bias=True)\n",
      "  (test_layer): Linear(in_features=100, out_features=25, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.01)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_dict = torch.load(\"/home/ubuntu/SindiLab/NACT/ClassifierWeights/pbmc-Best_model_Best.pth\")\n",
    "\n",
    "nact = model_dict[\"Saved_Model\"]\n",
    "\n",
    "print(nact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the device where you want to generate data from\n",
    "\n",
    "We recommend using GPUs for *training*, but for inference either CPUs or GPUs should work just fine (but GPUs would be faster). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU (CUDA)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if str(device) == \"cuda\":\n",
    "    print('Using GPU (CUDA)')\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Data\n",
    "\n",
    "Let us load in the test data set now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NACT.utils import *\n",
    "from NACT import Scanpy_IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Reading in Scanpy/Seurat AnnData\n",
      "    -> Splitting Train and Validation Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/categorical.py:2487: FutureWarning: The `inplace` parameter in pandas.Categorical.remove_unused_categories is deprecated and will be removed in a future version.\n",
      "  res = method(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Using cluster info for generating train and validation labels\n",
      "==> Checking if we have sparse matrix into dense\n",
      "    -> Seems the data is dense\n",
      "==> sample of the training data: tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000, 16.4474,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, 11.3572,  0.0000]])\n",
      "==> sample of the test data: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "_, test_data_loader = Scanpy_IO('/home/ubuntu/RawData/68kPBMCs_preprocessed.h5ad',\n",
    "                                                        test_no_valid = True,\n",
    "                                                        log=False,\n",
    "                                                        verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the `evaluate_classifier` function for a full report!\n",
    "\n",
    "We provide easy-to-use utilities for making things easier. One of these utility functions is `evaluate_classifier`, which provides a full classification report if wanted (using `sklearn`). (valid_data_loader, model,classification_report=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Evaluating on Validation Set:\n",
      "    -> Accuracy of classifier network on validation set: 92.2329 %\n",
      "    -> Non-Weighted F1 Score on validation set: 0.7482 \n",
      "    -> Weighted F1 Score on validation set: 0.9217 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.90      0.90      1791\n",
      "         1.0       0.88      0.88      0.88      1545\n",
      "         2.0       0.95      0.96      0.95      1515\n",
      "         3.0       0.90      0.90      0.90       697\n",
      "         4.0       0.99      0.99      0.99       483\n",
      "         5.0       0.97      0.97      0.97       466\n",
      "         6.0       1.00      0.99      1.00       413\n",
      "         7.0       0.97      0.85      0.90        71\n",
      "         8.0       0.00      0.00      0.00         8\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92      6991\n",
      "   macro avg       0.75      0.74      0.75      6991\n",
      "weighted avg       0.92      0.92      0.92      6991\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0., 2., 4., ..., 2., 4., 3.]),\n",
       " array([0., 2., 4., ..., 2., 4., 3.]),\n",
       " 0.7482368776409196)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classifier(test_data_loader, nact, classification_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
