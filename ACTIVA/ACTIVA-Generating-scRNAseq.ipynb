{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTIVA Tutorial: Generating Realistic scRNA-Seq\n",
    "\n",
    "In this notebook, we will go over how to load a pre-trained ACTIVA model, and how to generate synthetic data using the generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in pre-trained ACTIVA model\n",
    "\n",
    "Since our implementation is in pytorch, we can use the `load` funtion that pytorch provides. Our model is stored as a dict, with `epoch` corresponding to the current epoch, and `Saved_Model` corresponding to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCIV(\n",
      "  (encoder): Encoder(\n",
      "    (enc_sequential): Sequential(\n",
      "      (0): Linear(in_features=17789, out_features=1024, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (4): ReLU()\n",
      "      (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (7): ReLU()\n",
      "      (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (10): ReLU()\n",
      "      (11): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (lsn): LSN()\n",
      "    (thres_layer): ReLU()\n",
      "    (dec_sequential): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (4): ReLU()\n",
      "      (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (7): ReLU()\n",
      "      (8): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): Linear(in_features=1024, out_features=17789, bias=True)\n",
      "      (10): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "# here is the path to a pre-trained ACTIVA model\n",
    "path_to_pretrained = \"/home/ubuntu/SindiLab/ACTIVA-Saved_Model/model_epoch_600_iter_0.pth\"\n",
    "\n",
    "model_dict = torch.load(path_to_pretrained)\n",
    "\n",
    "activa = model_dict[\"Saved_Model\"]\n",
    "\n",
    "print(activa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the device where you want to generate data from\n",
    "\n",
    "We recommend using GPUs for *training*, but for inference either CPUs or GPUs should work just fine (but GPUs would be faster). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU (CUDA)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if str(device) == \"cuda\":\n",
    "    print('Using GPU (CUDA)')\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Gaussian noise latent tensors for input to the generator\n",
    "\n",
    "As mentioned in our paper, we use an VAE (IntroVAEs to be exact) as the core of our model. That means that after training the model, we can input noise tensors to the generator which then maps them to the same manifold as the single cell data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We generated 6991 cells in 0.5929989814758301 seconds (on cuda)\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "start = time.time()\n",
    "\n",
    "# for reproducibility \n",
    "torch.manual_seed(0)\n",
    "\n",
    "num_cells = 6991\n",
    "# look at the input size to the generator network of ACTIVA\n",
    "latent_dim = 128;\n",
    "z_g = torch.randn(num_cells, latent_dim).to(device)\n",
    "# generate synthetic cells with ACTIVA\n",
    "generated_cells = activa.decoder(z_g)\n",
    "\n",
    "count_matrix = generated_cells.detach().cpu().numpy()\n",
    "\n",
    "print(f\"We generated {num_cells} cells in {time.time() - start} seconds (on {device})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning count matrix into a Compressed Sparse Row matrix\n",
    "\n",
    "here we will sparsify  our matrix (into a CSR matrix) for faster computations and less storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "count_matrix_sparse = sp.csr_matrix(count_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the gene-names with the generated data\n",
    "\n",
    "Here we will read in the original AnnData object, and replace the count matrix with the ones we generated. This is because our model doesn't know the specific gene names, but it is aware of the importance of each feature in the columns. So replacing the count matrix with the generated ones (and keeping the rest of the AnnData object) allows us to do analysis with the gene names included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 6991 × 17789\n",
      "    obs: 'cluster', 'n_genes', 'n_counts', 'split'\n",
      "    var: 'n_cells'\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "# read in the original data \n",
    "adata = sc.read(\"/home/ubuntu/RawData/raw_68kPBMCs.h5ad\")\n",
    "\n",
    "# now make the count matrix to have the same size as the generated cells (since we will replace this in the next step)\n",
    "\n",
    "sc.pp.subsample(adata, n_obs=num_cells, random_state=0, copy=False)\n",
    "\n",
    "adata.X = count_matrix_sparse;\n",
    "\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 6991 × 17789\n",
      "    obs: 'n_genes', 'n_counts'\n",
      "    var: 'n_cells'\n"
     ]
    }
   ],
   "source": [
    "# delete the extra attributes that the original data had \n",
    "del adata.obs[\"cluster\"]\n",
    "del adata.obs[\"split\"]\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the generated cells as a Scanpy object\n",
    "\n",
    "now we will save as a Scanpy object, which can be used in Seurat as well (as we do for post processing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the new cells to ./ACTIVA-Generated/68kPBMC-6991Generated.h5ad.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# check if the directory exists \n",
    "dir_name = 'ACTIVA-Generated'\n",
    "if not os.path.isdir(dir_name):\n",
    "    os.mkdir(dir_name) \n",
    "    print(f\"Created {dir_name} directory\") \n",
    "\n",
    "path = \"./\" + dir_name + f\"/68kPBMC-{num_cells}Generated.h5ad\"\n",
    "adata.write(path)\n",
    "print(f\"Saved the new cells to {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and that is it. In another tutorial, we will go over performing postprocessing with Seurat, and generating specific cell-types using ACTIVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
