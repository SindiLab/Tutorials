{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of using SCProcessing package to make training splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "\n",
    "Make sure `SCprocessing` is installed and ready to go : )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Preprocessing: importing scanpy (may take a second)\n",
      "WARNING:root:Preprocessing: Importing Done\n",
      "WARNING:root:TrainingSplit: importing scanpy (may take a second)\n",
      "WARNING:root:TrainingSplit: importing Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from SCProcessing import TrainSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data\n",
    "\n",
    "Read in the scanpy data you want to split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(\"/home/ubuntu/COVID_Data/NeuroCOVID/NeuroCOVID_Preprocessed_Logged&Clustered.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 78172 × 22807\n",
       "    obs: 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'percent_mt2', 'n_counts', 'n_genes', 'louvain'\n",
       "    var: 'gene_ids', 'feature_types', 'mt', 'ribo', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells'\n",
       "    uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'umap'\n",
       "    obsm: 'X_pca', 'X_umap'\n",
       "    varm: 'PCs'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass in the object to `TrainSplit` class\n",
    "\n",
    "So first, we want to make sure that we create an object of `TrainSplit` class, so that we could call all of its method. Here is the usage of this class:\n",
    "\n",
    "`__init__(self, data, trainNumber, validationNumber, testNumber, balancedSplit:bool=True, randSeed:int=0, clusterRes=None, savePath = None)`\n",
    "\n",
    "Where `trainNumber` is the number of training samples, `testNumber` and `validNumber` are the number of testing and validation. Note that if you choose balance split (recommended), i.e. `balanceSplit=True`, then these numbers may be slightly off becuase the proportions are being considered. If clustering is not done already, `clusterRes` is the resolution of the clustering that will be done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = TrainSplit(adata, 70000, 0, 8172, balancedSplit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Information\n",
    "\n",
    "If the data is already clustered, we only need to get the cluster ratios for a balance split. Make sure that the `scanpy` object has an attribute under `obs` that is called `cluster`, e.g. `adata.obs[\"cluster\"]` exists. If data is ***not clustered***, then you can run `obj.Cluster()` first, and then continue on exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IF CLUSTERING IS NOT DONE ALREADY!\n",
    "# obj.Cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved cluster ratios to object attributes\n"
     ]
    }
   ],
   "source": [
    "obj.Cluster_ratios()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Cluster Ratios exist\n",
      "INFO:root:Starting a *balanced* split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a *balanced* split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/categorical.py:2487: FutureWarning: The `inplace` parameter in pandas.Categorical.remove_unused_categories is deprecated and will be removed in a future version.\n",
      "  res = method(*args, **kwargs)\n",
      "INFO:root:Splitting done\n"
     ]
    }
   ],
   "source": [
    "obj.Split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now inspect the orginal data to make sure we have an attribute called `split`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 78172 × 22807\n",
       "    obs: 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'percent_mt2', 'n_counts', 'n_genes', 'louvain', 'cluster', 'split'\n",
       "    var: 'gene_ids', 'feature_types', 'mt', 'ribo', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells'\n",
       "    uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'umap'\n",
       "    obsm: 'X_pca', 'X_umap'\n",
       "    varm: 'PCs'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.sc_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the new `scanpy` object\n",
    "\n",
    "Now we can save the object to a `h5ad` file. If we do not provide a path, the object is saved to a directory `./TrainSplitData` with a JSON of the hyperparameters, and the actual `h5ad` file containing the object. Alternatively, you can provide a path initially when you make the `TrainSplit` object under `savePath`, but this is not necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saving data and parameters to folder ./TrainSplitData/TrainSplit.h5ad\n"
     ]
    }
   ],
   "source": [
    "obj.Save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
