{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of using SCProcessing package to make training splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "\n",
    "Make sure `SCprocessing` is installed and ready to go : )\n",
    "\n",
    "you can do so in this notebook using \n",
    "\n",
    "`!pip install -e <PATH/TO/WHERE/SETUP.PY FOR THIS PACKAGE RESIDES>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Preprocessing: importing scanpy (may take a second)\n",
      "WARNING:root:Preprocessing: Importing Done\n",
      "WARNING:root:TrainingSplit: importing scanpy (may take a second)\n",
      "WARNING:root:TrainingSplit: importing Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from SCProcessing import TrainSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data\n",
    "\n",
    "Read in the scanpy data you want to split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(\"/home/jovyan/NACT_Project/N-ACT_Data/pbmc68k_filt_BP.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 66084 × 20387\n",
       "    var: 'gene_ids'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass in the object to `TrainSplit` class\n",
    "\n",
    "So first, we want to make sure that we create an object of `TrainSplit` class, so that we could call all of its method. Here is the usage of this class:\n",
    "\n",
    "`__init__(self, data, trainNumber, validationNumber, testNumber, balancedSplit:bool=True, randSeed:int=0, clusterRes=None, savePath = None)`\n",
    "\n",
    "Where `trainNumber` is the number of training samples, `testNumber` and `validNumber` are the number of testing and validation. Note that if you choose balance split (recommended), i.e. `balanceSplit=True`, then these numbers may be slightly off becuase the proportions are being considered. If clustering is not done already, `clusterRes` is the resolution of the clustering that will be done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = TrainSplit(adata, 59000, 0, 7084, balancedSplit=True, clusterRes = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Information\n",
    "\n",
    "If the data is already clustered, we only need to get the cluster ratios for a balance split. Make sure that the `scanpy` object has an attribute under `obs` that is called `cluster`, e.g. `adata.obs[\"cluster\"]` exists. If data is ***not clustered***, then you can run `obj.Cluster()` first, and then continue on exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Starting to cluster\n",
      "    -> Setting clustering resolution to 0.35\n",
      "    -> Running PCA:\n",
      "    -> PCA done.\n",
      "    -> Clustering:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "OMP: Info #271: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Saving cluster ratios:\n",
      "    -> Number of clusters: 10\n",
      "-><- Saved cluster ratios to object attributes\n",
      "-><- Done. Clustering of the raw data is done to 10 clusters.\n",
      " Clustering took 224.00557947158813 seconds\n"
     ]
    }
   ],
   "source": [
    "## IF CLUSTERING IS NOT DONE ALREADY! \n",
    "obj.Cluster(clusterRes=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IF CLUSTERING IS ALREADY DONE! \n",
    "# obj.Cluster_ratios()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:    -> Cluster Ratios exist\n",
      "INFO:root:    -> Starting a *balanced* split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Splitting:\n",
      "    -> Starting a *balanced* split\n",
      "-><- Splitting done\n",
      "Splitting took 1.7139842510223389 seconds\n"
     ]
    }
   ],
   "source": [
    "obj.Split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now inspect the orginal data to make sure we have an attribute called `split`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 66084 × 20387\n",
       "    obs: 'cluster', 'split'\n",
       "    var: 'gene_ids'\n",
       "    obsm: 'X_pca'\n",
       "    varm: 'PCs'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.sc_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the new `scanpy` object\n",
    "\n",
    "Now we can save the object to a `h5ad` file. If we do not provide a path, the object is saved to a directory `./TrainSplitData` with a JSON of the hyperparameters, and the actual `h5ad` file containing the object. Alternatively, you can provide a path initially when you make the `TrainSplit` object under `savePath`, but this is not necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Saving processed data:\n",
      "    -> Saving data and parameters to folder ./TrainTestSplitData/TrainTestSplit.h5ad\n",
      "-><- Saving done.\n"
     ]
    }
   ],
   "source": [
    "obj.Save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
