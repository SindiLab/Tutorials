{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTINN-Pytorch Tutorial: Classifying NeuroCOVID scRNAseq\n",
    "\n",
    "In this notebook, we will go over how to load a pre-trained ACTINN model, and how to make predictions and evaluate the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in pre-trained ACTINN model\n",
    "\n",
    "Since our implementation is in pytorch, we can use the `load` funtion that pytorch provides. Our model is stored as a dict, with `epoch` corresponding to the current epoch, and `Saved_Model` corresponding to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (classifier_sequential): Sequential(\n",
      "    (0): Linear(in_features=22807, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=50, out_features=25, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=25, out_features=20, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "model_dict = torch.load(\"/home/ubuntu/SindiLab/ACTINN-PyTorch/ClassifierWeights/NeruoCOVID_model_epoch_50_iter_0.pth\")\n",
    "\n",
    "actinn = model_dict[\"Saved_Model\"]\n",
    "\n",
    "print(actinn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the device where you want to generate data from\n",
    "\n",
    "We recommend using GPUs for *training*, but for inference either CPUs or GPUs should work just fine (but GPUs would be faster). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU (CUDA)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if str(device) == \"cuda\":\n",
    "    print('Using GPU (CUDA)')\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Data\n",
    "\n",
    "Let us load in the test data set now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ACTINN.utils import *\n",
    "from ACTINN import Scanpy_IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Reading in Scanpy/Seurat AnnData\n",
      "    -> Splitting Train and Validation Data\n",
      "==> Using cluster info for generating train and validation labels\n",
      "==> Checking if we have sparse matrix into dense\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/categorical.py:2487: FutureWarning: The `inplace` parameter in pandas.Categorical.remove_unused_categories is deprecated and will be removed in a future version.\n",
      "  res = method(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> sample of the training data: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "==> sample of the test data: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "_, test_data_loader = Scanpy_IO('/home/ubuntu/RawData/78KNeuroCOVID_preprocessed_splitted_logged.h5ad',\n",
    "                                                        test_no_valid = True,\n",
    "                                                        log=False,\n",
    "                                                        verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the `evaluate_classifier` function for a full report!\n",
    "\n",
    "We provide easy-to-use utilities for making things easier. One of these utility functions is `evaluate_classifier`, which provides a full classification report if wanted (using `sklearn`). (valid_data_loader, model,classification_report=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Evaluating on Validation Set:\n",
      "    -> Accuracy of classifier network on validation set: 97.9054 %\n",
      "    -> Non-Weighted F1 Score on validation set: 0.9697 \n",
      "    -> Weighted F1 Score on validation set: 0.9790 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      2067\n",
      "         1.0       0.99      1.00      0.99      1077\n",
      "         2.0       0.96      0.96      0.96       781\n",
      "         3.0       0.96      0.96      0.96       780\n",
      "         4.0       0.97      0.97      0.97       760\n",
      "         5.0       0.99      0.98      0.98       514\n",
      "         6.0       0.98      0.98      0.98       366\n",
      "         7.0       0.99      0.99      0.99       345\n",
      "         8.0       0.98      0.99      0.99       297\n",
      "         9.0       1.00      0.99      1.00       295\n",
      "        10.0       0.99      0.97      0.98       159\n",
      "        11.0       0.98      0.93      0.96       137\n",
      "        12.0       0.98      0.90      0.94       102\n",
      "        13.0       0.92      0.94      0.93       100\n",
      "        14.0       0.96      0.96      0.96        98\n",
      "        15.0       0.94      1.00      0.97        75\n",
      "        16.0       0.97      0.88      0.92        73\n",
      "        17.0       0.96      0.98      0.97        54\n",
      "        18.0       1.00      1.00      1.00        42\n",
      "        19.0       0.95      0.95      0.95        42\n",
      "\n",
      "    accuracy                           0.98      8164\n",
      "   macro avg       0.97      0.97      0.97      8164\n",
      "weighted avg       0.98      0.98      0.98      8164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(test_data_loader, actinn, classification_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
